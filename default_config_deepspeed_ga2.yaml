compute_environment: LOCAL_MACHINE                                                                                                                                                                                                
deepspeed_config:
  gradient_accumulation_steps: 2
  gradient_clipping: 1.0
  offload_optimizer_device: none
  offload_param_device: none
  zero3_init_flag: false
  zero_stage: 2
distributed_type: DEEPSPEED
downcast_bf16: 'no'
dynamo_config:
  dynamo_backend: INDUCTOR   
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 8
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false





# dynamo_backend: INDUCTOR  代表启用 TorchInductor：
# 训练/推理时 accelerate 会自动用 torch.compile(..., backend="inductor") 包装模型，
# 借助 Triton 生成高度优化的 GPU/CPU Kernel，以获得 10%～40% 不等的加速（视模型与硬件而定）。

# 若想关闭编译或切换后端，可把该字段改成 EAGER、AOT_EAGER 等，或直接删除 dynamo_config 块。